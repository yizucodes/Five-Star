{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cell - Essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_theme()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1689188 reviews\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "def load_data():\n",
    "    \"\"\"Load the explored dataset from previous notebook\"\"\"\n",
    "    try:\n",
    "        df = pd.read_json('../data/raw/reviews_Electronics_5.json.gz', lines=True)\n",
    "        print(f\"Loaded {len(df)} reviews\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing class\n",
    "class ReviewPreprocessor:\n",
    "    \"\"\"Class to handle all preprocessing steps for Amazon reviews\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Common English stopwords - we can define these ourselves\n",
    "        self.stop_words = {\n",
    "            'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "            \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', \n",
    "            'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', \n",
    "            'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', \n",
    "            'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', \n",
    "            'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', \n",
    "            'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', \n",
    "            'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', \n",
    "            'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "            'with', 'about', 'against', 'between', 'into', 'through', 'during', \n",
    "            'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "            'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', \n",
    "            'then', 'once'\n",
    "        }\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean review text\"\"\"\n",
    "        if not isinstan=ce(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\"Remove stopwords without using NLTK\"\"\"\n",
    "        # Simple word splitting (no need for complex tokenization)\n",
    "        words = text.split()\n",
    "        # Remove stopwords\n",
    "        filtered_words = [word for word in words if word not in self.stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "    \n",
    "    def process_dates(self, df):\n",
    "        \"\"\"Process and format dates\"\"\"\n",
    "        df['review_date'] = pd.to_datetime(df['unixReviewTime'], unit='s')\n",
    "        df['formatted_date'] = df['review_date'].dt.strftime('%B %d, %Y')\n",
    "        return df\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        \"\"\"Create additional features\"\"\"\n",
    "        df['review_length'] = df['reviewText'].str.len()\n",
    "        df['word_count'] = df['reviewText'].str.split().str.len()\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified preprocessing function without batching (since we only have 5000 reviews)\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Main preprocessing pipeline\"\"\"\n",
    "    # Create a copy and reset index\n",
    "    df = df.copy()\n",
    "    df = df.reset_index(drop=True)  # This fixes the indexing issue\n",
    "    \n",
    "    preprocessor = ReviewPreprocessor()\n",
    "    print(f\"Starting preprocessing pipeline for {len(df)} reviews...\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    initial_size = len(df)\n",
    "    df = df.drop_duplicates(subset=['reviewText'])\n",
    "    print(f\"Removed {initial_size - len(df)} duplicate reviews\")\n",
    "    \n",
    "    print(\"Cleaning text and removing stopwords...\")\n",
    "    # Process all reviews at once (no batching needed for 5000 reviews)\n",
    "    df['cleaned_text'] = df['reviewText'].apply(preprocessor.clean_text)\n",
    "    df['processed_text'] = df['cleaned_text'].apply(preprocessor.remove_stopwords)\n",
    "    \n",
    "    # Process dates and create features\n",
    "    df = preprocessor.process_dates(df)\n",
    "    df = preprocessor.create_features(df)\n",
    "    \n",
    "    print(\"Preprocessing complete!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification function\n",
    "def verify_preprocessing(df):\n",
    "    \"\"\"Verify the preprocessing results\"\"\"\n",
    "    print(\"Preprocessing Verification:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"\\n1. Data Shape:\")\n",
    "    print(f\"Number of reviews: {len(df)}\")\n",
    "    \n",
    "    print(\"\\n2. Text Cleaning Check:\")\n",
    "    print(\"Sample original text:\")\n",
    "    print(df['reviewText'].iloc[0][:200])\n",
    "    print(\"\\nSample cleaned text:\")\n",
    "    print(df['processed_text'].iloc[0][:200])\n",
    "    \n",
    "    print(\"\\n3. Feature Statistics:\")\n",
    "    print(df[['review_length', 'word_count']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save function to save data in csv\n",
    "def save_processed_data(df, filename='../data/processed/processed_reviews.csv'):\n",
    "    \"\"\"Save the processed dataset\"\"\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved processed data to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Reviews Information:\n",
      "--------------------------------------------------\n",
      "Date range: 2014-07-15 00:00:00 to 2014-07-23 00:00:00\n",
      "Number of reviews: 5000\n",
      "Starting preprocessing pipeline for 5000 reviews...\n",
      "Removed 32 duplicate reviews\n",
      "Cleaning text and removing stopwords...\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent 5000 reviews up until July 2014\n",
    "df['review_date'] = pd.to_datetime(df['unixReviewTime'], unit='s')\n",
    "cutoff_date = '2014-07-31'\n",
    "\n",
    "# Filter and sort\n",
    "recent_reviews = df[df['review_date'] <= cutoff_date].sort_values('review_date', ascending=False).head(5000)\n",
    "\n",
    "print(\"Selected Reviews Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Date range: {recent_reviews['review_date'].min()} to {recent_reviews['review_date'].max()}\")\n",
    "print(f\"Number of reviews: {len(recent_reviews)}\")\n",
    "\n",
    "# Now process these reviews\n",
    "processed_sample = preprocess_data(recent_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Verification:\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Data Shape:\n",
      "Number of reviews: 4968\n",
      "\n",
      "2. Text Cleaning Check:\n",
      "Sample original text:\n",
      "Helps out tremendously.\n",
      "\n",
      "Sample cleaned text:\n",
      "helps tremendously\n",
      "\n",
      "3. Feature Statistics:\n",
      "       review_length   word_count\n",
      "count    4968.000000  4968.000000\n",
      "mean      514.063607    93.649557\n",
      "std       844.144106   150.748031\n",
      "min         0.000000     0.000000\n",
      "25%        85.000000    16.000000\n",
      "50%       226.000000    43.000000\n",
      "75%       564.250000   105.000000\n",
      "max     15312.000000  2734.000000\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Verify sample processing\n",
    "verify_preprocessing(processed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to ../data/processed/processed_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "# Save processed data\n",
    "save_processed_data(processed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING COMPLETION CHECKLIST\n",
      "==================================================\n",
      "\n",
      "1. DATA REQUIREMENTS:\n",
      "------------------------------\n",
      "✓ Number of reviews: 4968 (~5000 required)\n",
      "✓ Date range: 2014-07-15 00:00:00 to 2014-07-23 00:00:00\n",
      "  (Should be up to July 2014)\n",
      "\n",
      "2. DATA QUALITY:\n",
      "------------------------------\n",
      "✓ Missing values:\n",
      "reviewerName    1020\n",
      "dtype: int64\n",
      "✓ Empty reviews: 2\n",
      "\n",
      "3. TEXT PROCESSING:\n",
      "------------------------------\n",
      "✓ Text cleaning verification:\n",
      "  Original: Helps out tremendously....\n",
      "  Cleaned:  helps out tremendously...\n",
      "  Final:    helps tremendously...\n",
      "\n",
      "4. REQUIRED FEATURES:\n",
      "------------------------------\n",
      "✓ Required columns: All present\n",
      "\n",
      "5. BASIC STATISTICS:\n",
      "------------------------------\n",
      "✓ Average word count: 93.6\n",
      "✓ Rating distribution:\n",
      "overall\n",
      "1     271\n",
      "2     232\n",
      "3     423\n",
      "4     985\n",
      "5    3057\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_completion_check(df):\n",
    "    \"\"\"Comprehensive check to verify preprocessing completion\"\"\"\n",
    "    print(\"PREPROCESSING COMPLETION CHECKLIST\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Data Volume and Date Range\n",
    "    print(\"\\n1. DATA REQUIREMENTS:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"✓ Number of reviews: {len(df)} (~5000 required)\")\n",
    "    print(f\"✓ Date range: {df['review_date'].min()} to {df['review_date'].max()}\")\n",
    "    print(\"  (Should be up to July 2014)\")\n",
    "    \n",
    "    # 2. Data Quality\n",
    "    print(\"\\n2. DATA QUALITY:\")\n",
    "    print(\"-\" * 30)\n",
    "    # Check for missing values\n",
    "    missing = df.isnull().sum()\n",
    "    print(\"✓ Missing values:\")\n",
    "    print(missing[missing > 0] if any(missing > 0) else \"None\")\n",
    "    \n",
    "    # Check for empty reviews\n",
    "    empty_reviews = len(df[df['processed_text'].str.len() == 0])\n",
    "    print(f\"✓ Empty reviews: {empty_reviews}\")\n",
    "    \n",
    "    # 3. Text Processing\n",
    "    print(\"\\n3. TEXT PROCESSING:\")\n",
    "    print(\"-\" * 30)\n",
    "    # Sample a review to check cleaning\n",
    "    sample = df.iloc[0]\n",
    "    print(\"✓ Text cleaning verification:\")\n",
    "    print(f\"  Original: {sample['reviewText'][:100]}...\")\n",
    "    print(f\"  Cleaned:  {sample['cleaned_text'][:100]}...\")\n",
    "    print(f\"  Final:    {sample['processed_text'][:100]}...\")\n",
    "    \n",
    "    # 4. Required Features\n",
    "    print(\"\\n4. REQUIRED FEATURES:\")\n",
    "    print(\"-\" * 30)\n",
    "    required_columns = [\n",
    "        'reviewText',        # Original text\n",
    "        'cleaned_text',      # Cleaned text\n",
    "        'processed_text',    # Final processed text\n",
    "        'review_date',       # Datetime\n",
    "        'formatted_date',    # Formatted date\n",
    "        'review_length',     # Length features\n",
    "        'word_count',\n",
    "        'overall'           # Rating\n",
    "    ]\n",
    "    \n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    print(\"✓ Required columns:\", \"All present\" if not missing_cols else f\"Missing: {missing_cols}\")\n",
    "    \n",
    "    # 5. Statistics\n",
    "    print(\"\\n5. BASIC STATISTICS:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"✓ Average word count: {df['word_count'].mean():.1f}\")\n",
    "    print(f\"✓ Rating distribution:\\n{df['overall'].value_counts().sort_index()}\")\n",
    "\n",
    "# Run the completion check\n",
    "preprocessing_completion_check(processed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL CLEANING STEPS\n",
      "--------------------------------------------------\n",
      "✓ Filled 0 missing reviewer names with 'Anonymous'\n",
      "\n",
      "Empty Reviews Found:\n",
      "------------------------------\n",
      "Review 2017:\n",
      "Original text: \n",
      "Cleaned text: \n",
      "Rating: 4\n",
      "------------------------------\n",
      "Review 3935:\n",
      "Original text: I have about 8 of them.\n",
      "Cleaned text: i have about of them\n",
      "Rating: 5\n",
      "------------------------------\n",
      "\n",
      "✓ Removed 2 empty reviews\n",
      "\n",
      "FINAL VERIFICATION:\n",
      "------------------------------\n",
      "Final number of reviews: 4966\n",
      "\n",
      "Missing values check:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Empty reviews check: 0\n",
      "\n",
      "Saved final cleaned dataset\n",
      "\n",
      "FINAL STATUS CHECK:\n",
      "PREPROCESSING COMPLETION CHECKLIST\n",
      "==================================================\n",
      "\n",
      "1. DATA REQUIREMENTS:\n",
      "------------------------------\n",
      "✓ Number of reviews: 4966 (~5000 required)\n",
      "✓ Date range: 2014-07-15 00:00:00 to 2014-07-23 00:00:00\n",
      "  (Should be up to July 2014)\n",
      "\n",
      "2. DATA QUALITY:\n",
      "------------------------------\n",
      "✓ Missing values:\n",
      "None\n",
      "✓ Empty reviews: 0\n",
      "\n",
      "3. TEXT PROCESSING:\n",
      "------------------------------\n",
      "✓ Text cleaning verification:\n",
      "  Original: Helps out tremendously....\n",
      "  Cleaned:  helps out tremendously...\n",
      "  Final:    helps tremendously...\n",
      "\n",
      "4. REQUIRED FEATURES:\n",
      "------------------------------\n",
      "✓ Required columns: All present\n",
      "\n",
      "5. BASIC STATISTICS:\n",
      "------------------------------\n",
      "✓ Average word count: 93.7\n",
      "✓ Rating distribution:\n",
      "overall\n",
      "1     271\n",
      "2     232\n",
      "3     423\n",
      "4     984\n",
      "5    3056\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean missing values and empty reviews\n",
    "def final_cleaning(df):\n",
    "    \"\"\"Final cleaning steps for the dataset\"\"\"\n",
    "    print(\"FINAL CLEANING STEPS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 1. Handle Missing Reviewer Names\n",
    "    initial_missing = df['reviewerName'].isnull().sum()\n",
    "    df['reviewerName'] = df['reviewerName'].fillna('Anonymous')\n",
    "    print(f\"✓ Filled {initial_missing} missing reviewer names with 'Anonymous'\")\n",
    "    \n",
    "    # 2. Handle Empty Reviews\n",
    "    initial_empty = df[df['processed_text'].str.len() == 0]\n",
    "    print(\"\\nEmpty Reviews Found:\")\n",
    "    print(\"-\" * 30)\n",
    "    for idx, review in initial_empty.iterrows():\n",
    "        print(f\"Review {idx}:\")\n",
    "        print(f\"Original text: {review['reviewText']}\")\n",
    "        print(f\"Cleaned text: {review['cleaned_text']}\")\n",
    "        print(f\"Rating: {review['overall']}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    # Remove empty reviews\n",
    "    df = df[df['processed_text'].str.len() > 0]\n",
    "    print(f\"\\n✓ Removed {len(initial_empty)} empty reviews\")\n",
    "    \n",
    "    # Final verification\n",
    "    print(\"\\nFINAL VERIFICATION:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Final number of reviews: {len(df)}\")\n",
    "    print(\"\\nMissing values check:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "    print(\"\\nEmpty reviews check:\", len(df[df['processed_text'].str.len() == 0]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply final cleaning\n",
    "processed_df = final_cleaning(processed_sample)\n",
    "\n",
    "# Save the final cleaned dataset\n",
    "processed_df.to_csv('../data/processed/final_cleaned_reviews.csv', index=False)\n",
    "print(\"\\nSaved final cleaned dataset\")\n",
    "\n",
    "# Run the completion check again\n",
    "print(\"\\nFINAL STATUS CHECK:\")\n",
    "preprocessing_completion_check(processed_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
